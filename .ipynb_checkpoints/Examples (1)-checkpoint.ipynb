{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values and Olympic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open missing_values.csv in text file \n",
    "# and in excel to see how it looks like\n",
    "df = pd.read_csv('missing_values.csv')\n",
    "#print(df)\n",
    "print(\"df.head(5).append(df.tail(6))\") # how to append head and tail or concatenate\n",
    "print(df.head(5).append(df.tail(6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which elements are NaN in the DataFrame ( Display True and False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the first five rows on records which contains null\n",
    "df = pd.read_csv('missing_values.csv')\n",
    "print(f'\\nUsing df.isna()\\n {df.isna().head()}') # using isna\n",
    "#Alternatively\n",
    "print(f'\\nUsing df.isnull()\\n {df.isnull().head()}') #using isnull\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which elements are NOT NaN in the DataFrame ( Display True and False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(f'\\nUsing df.notna()\\n {df.notna().head()}')\n",
    "#alternatively\n",
    "print(f'\\nUsing df.notnull()\\n {df.notnull().head()}') # using notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display records in which elements are NaN in column 'paused' and how many are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(f'df.head()\\n {df.head()}')\n",
    "print(f\"\\nRecords in which column 'paused' is NaN'\")\n",
    "#Alternatives\n",
    "#print(df[df.paused.isna()])\n",
    "#print(df[df.paused.isnull()])\n",
    "#print(df[df['paused'].isna()])\n",
    "print(df[df['paused'].isnull()])\n",
    "#How many are they\n",
    "df3=df[df['paused'].isnull()]\n",
    " #use any column for counting\n",
    "print(f'\\nThere are {df3.user.size} records which meets criteria')\n",
    "#alternatively\n",
    "#print(f'\\nThere are {df3.shape[0]} records which meets criteria')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SELF STUDY - Number of NaN in each column - use sum() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "#print(\"df.head()=\\n\",df)\n",
    "print(\"\\nNumber of null in each column\")\n",
    "print(df.isna().sum())  # defaults to column 0\n",
    "print(\"\\nalternatively using axis=0 or axis='index'\")\n",
    "print(df.isna().sum(axis=0))\n",
    "#alternatively\n",
    "#print(df.isna().sum(axis='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  SELF STUDY - Number of NOT NaN in each column - use sum()) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(f'df.head()=\\n {df.head()}')\n",
    "print('\\nNumber of NOT null in each column')\n",
    "print(df.notna().sum())\n",
    "#alternatively\n",
    "#print(df.notna().sum(axis=0))\n",
    "#alternatively\n",
    "#print(df.notna().sum(axis='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  SELF STUDY - Number of NaN in each row (display 5 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(f'df.head()=\\n {df.head()}')\n",
    "print(\"\\nNumber of null in each row (first FIVE rows)\")\n",
    "print(df.isna().sum(axis=1).head())\n",
    "#alternatively\n",
    "#print(df.isna().sum(axis='columns').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  SELF STUDY - Number of NOT NaN in each row (display 5 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(f'df.head()=\\n {df.head()}')\n",
    "print(\"\\nNumber of NOT null in each row (first FIVE rows)\")\n",
    "print(df.notna().sum(axis=1).head())\n",
    "#alternatively\n",
    "#print(df.notna().sum(axis='columns').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  SELF STUDY - Total number of NaN in the whole dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(f'\\nNumber of NaN elements in a Dataframe is: {df.isna().sum().sum()}')\n",
    "#Qtn: Why do we need double sum().sum()?\n",
    "print(\"\\nNumber of NaN elements in each column:\\n \",df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SELF STUDY - Using count() to count not NaN in rows or Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Non NaN in Columns using count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(f'Number of not NaN in each column is:\\n {df.count()}') # efault is axis=0\n",
    "#Alternatively\n",
    "#print(f'Number of not NaN in each column is:\\n {df.count(axis=0)}')\n",
    "#alternatively\n",
    "#print(f\"Number of not NaN in each column is:\\n {df.count(axis='index')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe function does not include NaN Values. \n",
    "#Check the value of count() in both columns\n",
    "print(f\"\\n Results of describe function\\n {df.describe(include='all')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Non NaN in Rows using count (Display first five rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(df.head())\n",
    "print(f'Number of not NaN in each row is:\\n {df.count(axis=1).head()}')\n",
    "#alternatively\n",
    "#print(f\"Number of not NaN in each row is:\\n {df.count(axis='columns').head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SELF STUDY - Deleting rows or columns with missing data\n",
    "## (Cleaning Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop any row whose ANY element is equal to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(df.head(10))\n",
    "print(\"\\nDrop the rows where at least one element is missing\")\n",
    "df.dropna(inplace=True) # using default parameters\n",
    "#alternatively\n",
    "print(\"Can use: df.dropna(axis=0,how='any', inplace=True)\\n\")\n",
    "#df.dropna(axis=0,how='any', inplace=True)\n",
    "#alternatively\n",
    "#df.dropna(axis='index',how='any', inplace=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop any column whose ANY element is equal to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(df.head())\n",
    "print(\"\\nDrop the columns where at least one element is missing\")\n",
    "print(\"df.dropna(axis='columns',how='any', inplace=True\")\n",
    "df.dropna(axis='columns',how='any', inplace=True)\n",
    "#alternatively\n",
    "#df.dropna(axis=1,how='any', inplace=True)\n",
    "print(f'\\ndf.head() =\\n {df.head()}')\n",
    "print()\n",
    "print(\"RESULTS: 'paused' and 'volume' columns are deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### drop all columns whose ALL elements are equal to NaN - VERY USEFULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(f'df.head(2)=\\n {df.head(2)}')\n",
    "print(\"dropna(axis='columns',how='all', inplace=True\")\n",
    "number_columns1=df.shape[1] #before deletion\n",
    "df.dropna(axis='columns',how='all', inplace=True)\n",
    "\n",
    "#alternatively\n",
    "#df.dropna(axis=1,how='all', inplace=True) # axis=1\n",
    "number_columns2=df.shape[1] #after deletion\n",
    "diff=number_columns1-number_columns2 # difference\n",
    "if diff==0:\n",
    "    print('\\nNo any column is deleted')\n",
    "else:\n",
    "    print(f'\\nNo. of columns deleted are: {diff}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### drop all rows whose ALL elements are equal to NaN - VERY USEFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(f'shape of df is: {df.shape}')\n",
    "number_rows1=df.shape[0]\n",
    "print(f'df.head()=\\n {df.head()}')\n",
    "df.dropna(axis='index',how='all', inplace=True) #axis=0\n",
    "#alternatively\n",
    "#df.dropna(axis=0,how='all', inplace=True)\n",
    "print(f'\\ndf.head() after drop is =\\n {df.head()}')\n",
    "print(f'Shape after deletion is: {df.shape}')\n",
    "number_rows2=df.shape[0]\n",
    "diff=number_rows2-number_rows1\n",
    "if diff==0:\n",
    "    print(' No any row deleted')\n",
    "else:\n",
    "    print(f'No. of rows deleted are: {diff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(f'df=\\n {df.head(7)}')\n",
    "#Modify row 3 column 'paused from NaN to non-NaN\n",
    "df.loc[2,'paused']=True\n",
    "#Modify row 4 column 'paused from NaN to non-NaN\n",
    "#df.loc[4,'paused']=False\n",
    "df.loc[4,'paused']=True\n",
    "\n",
    "print(f'\\ndf(head(7)=\\n {df.head(7)}')\n",
    "\n",
    "print(f'Number of not NaN in each column is:\\n {df.count()}')\n",
    "print(f'\\ndf.head(2) before drop =\\n {df.head(2)}')\n",
    "print('\\n Keep columns with at least 5 non-missing values')\n",
    "df.dropna(axis='columns',thresh=5,inplace=True)\n",
    "print(f'\\ndf.head(2) after drop =\\n {df.head(2)}') #'volume' is deleted\n",
    "print('\\nRESULTS: volume column is deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print('BEFORE DROPPING')\n",
    "print('\\nNumber of NOT null in each row (first FIVE rows)')\n",
    "print(df.notna().sum(axis=1).head(15))\n",
    "print('\\n Keep rows with at least 5 non-missing values')\n",
    "print(f\"df.dropna(axis='index',thresh=5,inplace=True\")\n",
    "df.dropna(axis='index',thresh=5,inplace=True)\n",
    "print('\\nNumber of NOT null in each row AFTER DROPPING')\n",
    "print(df.notna().sum(axis=1).head())\n",
    "print(f'\\ndf.head() =\\n {df.head()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace all NaN in a dataframe with a Scalar Value using fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('missing_values.csv')\n",
    "print(f'df.head(3)=\\n {df.head(3)}')\n",
    "print(f\"\\nNaN replaced with '-1':\")\n",
    "df.fillna(-1,inplace=True) #replace NAN with -1\n",
    "print(f'df.fillna(-1,inplace=True)\\n {df.head(3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace NaN on specified columns with specified values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NaN on a specified columns with specified values\n",
    "df = pd.read_csv('missing_values.csv')\n",
    "print(f'df.head(3)=\\n {df.head(3)}')\n",
    "values={'paused':-888,'volume':-999}\n",
    "df.fillna(values,inplace=True)\n",
    "print(\"\\ndf after filling NaN in columns 'paused' and 'volume'\")\n",
    "print(f'\\ndf.head(3)=\\n {df.head(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace Missing (or) Generic Values\n",
    "df = pd.DataFrame({'one':[10,20,30,40,50,-2],\n",
    "                    'two':[0,-5,38,46,57,60]})\n",
    "print(f'df=\\n {df}')\n",
    "df2=df.copy()\n",
    "print(f'df2 before replacement=\\n {df2}')\n",
    "print('df2.replace([-2, -5],0,inplace=True')\n",
    "df2.replace([-2, -5],0,inplace=True) # for all columns\n",
    "print(f'df2 after replacement=\\n {df2}')\n",
    "\n",
    "df3=df.copy()\n",
    "print(f'df3 before replacement=\\n {df3}')\n",
    "print('df3.replace({-2:9999,-5:1111},inplace=True')\n",
    "df3.replace({-2:9999,-5:1111},inplace=True) # for all columns using dict style\n",
    "print(f'df3 after replacement=\\n {df3}')\n",
    "\n",
    "df4=df.copy()\n",
    "print(f'df4 before replacement=\\n {df4}')\n",
    "print('\\n target each column seperately')\n",
    "print(\"df4.replace({'one': {-2: np.nan, -5: np.nan},\\\n",
    "      'two': {-2: np.nan, -5: np.nan}},inplace=True\")\n",
    "df4.replace({'one': {-2: np.nan, -5: np.nan},           #specific columns\n",
    "             'two': {-2: np.nan, -5: np.nan}},inplace=True)\n",
    "print(f'\\ndf4 after replacement=\\n {df4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'Names': ['Bob','Jessica','Mary','John','Mel'],\n",
    "      'Score': [76,-2,77,78,101]}\n",
    "df = pd.DataFrame(data)\n",
    "print(f'df before limiting=\\n {df}')\n",
    "\n",
    "print('\\nFind the indices for outliers')\n",
    "print(f\"df.loc[df['Score'] <= 0,'Score']: {df.loc[df['Score'] <= 0,'Score']}\")\n",
    "print(f\"df.loc[df['Score'] >= 100,'Score'] {df.loc[df['Score'] >= 100,'Score']}\") \n",
    "\n",
    "print(\"\\nLimit the minimum to be 0 and maximum to be 100\")\n",
    "print(\"df.loc[df['Grades'] <= 0,'Grades'] = 0\")\n",
    "print(\"df.loc[df['Grades'] >= 100,'Grades'] = 100\")\n",
    "df.loc[df['Score'] <= 0,'Score'] = 0\n",
    "df.loc[df['Score'] >= 100,'Score'] = 100\n",
    "print(f'\\ndf after limits=\\n {df}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s=pd.Series(['Tanzania','Kenya','Uganda','Rwanda','Burundi','South Sudan'])\n",
    "print(f's=\\n {s}')\n",
    "print(f'\\ns.str.lower():\\n {s.str.lower()}')\n",
    "print(f'\\ns.str.upper():\\n {s.str.upper()}')\n",
    "s2=s.str.lower() # s2 in lower cases\n",
    "s3=s.str.upper() # s3 in upper cases\n",
    "print(f's2=s.str.lower():\\n {s2}')\n",
    "print(f's3=s.str.upper():\\n {s3}')\n",
    "print('\\n Countries which starts with B:\\n')\n",
    "print(f\"s[s.str.startswith('B')]\\n {s[s.str.startswith('B')]}\")\n",
    "print(\"\\n Countries which ends with letter 'a':\\n\")\n",
    "print(f\"s[s.str.endswith('a')]\\n {s[s.str.endswith('a')]}\")\n",
    "print(\"\\n Countries which contains 'an':\\n\")\n",
    "print(f\"s[s.str.contains('an')]\\n {s[s.str.contains('an')]}\")\n",
    "s2=s.str.replace('Burundi', 'Zimbabwe')\n",
    "print(f\"\\ns2=s.str.replace('Burundi', 'Zimbabwe')=\\n {s2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'Names': ['Bob','Jessica','Mary','John','Mel'],\n",
    "      'Score': [76,-2,77,78,101]}\n",
    "df = pd.DataFrame(data)\n",
    "print(f'df before changing=\\n {df}')\n",
    "df['Names']=df['Names'].str.lower()\n",
    "print(f'\\ndf after changing Names to lower=\\n {df}')\n",
    "df['Names']=df['Names'].str.upper()\n",
    "print(f'\\ndf after changing names to upper\\n {df}')\n",
    "df['Names']=df['Names'].str.capitalize()\n",
    "print(f'df after changing names to capitalize\\n {df}')\n",
    "\n",
    "df = pd.DataFrame(data) # to reset df\n",
    "print('\\nNames which starts with letter J are:')\n",
    "print(df[df.Names.str.startswith('J')])\n",
    "print('\\nHow many names in Names column starts with letter J?')\n",
    "print(\"df.Names.str.startswith('J').sum()}\")\n",
    "print(f\"Number of records for which Names start with J are {df.Names.str.startswith('J').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Animal':    ['Falcon', 'Falcon','Parrot', 'Parrot'],\n",
    "                   'Max_Speed': [380., 370., 24., 26.]})\n",
    "print(f'df=\\n {df}')\n",
    "print('\\ngroupby with sum()')\n",
    "print(df.groupby('Animal').sum())\n",
    "print('\\ngroupby with mean()')\n",
    "print(df.groupby('Animal').mean())\n",
    "print('\\ngroupby with count()')\n",
    "print(df.groupby('Animal').count())\n",
    "print('\\ngroupby with size()')\n",
    "print(df.groupby('Animal').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': [1, 1, 2, 2],\n",
    "                   'B': [1, 2, 3, 4],\n",
    "                   'C': np.random.randn(4)})\n",
    "print(f'df=\\n {df}')\n",
    "print('\\nThe aggregation is for each column')\n",
    "print(f\"df.groupby('A').agg('min')\\n {df.groupby('A').agg('min')}\")\n",
    "\n",
    "print('\\nMultiple aggregations')\n",
    "print(\"df.groupby('A').agg(['min', 'max']\")\n",
    "print(df.groupby('A').agg(['min', 'max']))\n",
    "\n",
    "print('\\nSelect a column for aggregation')\n",
    "print(\"df.groupby('A').B.agg(['min', 'max']\")\n",
    "print(df.groupby('A').B.agg(['min', 'max']))\n",
    "\n",
    "print('\\nDifferent aggregations per column')\n",
    "print(\"df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})\")\n",
    "df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olympics dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open dataset, skiprows=4 \n",
    "#open olympics.csv in Excel and see why 4 rows are skipped\n",
    "df = pd.read_csv('olympics.csv',skiprows=4)\n",
    "#print(df.head())\n",
    "#NOC stands for National Olympic Committee\n",
    "df.head() # note the difference of using print and not using print. \n",
    "          # Must be the last statement in a cell for such display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many rows and how many columns in the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rows and columns : {df.shape}')\n",
    "print(f'Number of rows : {df.shape[0]}')\n",
    "print(f'Number of columns : {df.shape[1]}')\n",
    "print('alternatively for getting number of rows, pick any column and use size')\n",
    "print(f'Number of rows : {df.City.size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get info about dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rows and columns, name of columns, index,columns names and their data types\n",
    "print(df.info()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many null values in each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of NAN values in each column: \\n {df.isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the first 5 records for columns:Edition, City, Athlete and Medal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The first 5 records for columns Edition, City, Athlete and Medal are:\\n ')\n",
    "print(df[['Edition','City','Athlete','Medal']].head())  #can use ...head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternatively make a copy to protect original df\n",
    "print('The first 5 records for columns Edition, City, Athlete and Medal are:\\n ')\n",
    "df2=df[['Edition','City','Athlete','Medal']].copy() # to protect df\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of medals which were presented excluding NaN in descending order by default - utlize value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of medals which were presented are:\")\n",
    "print(df.Medal.value_counts(dropna=True))           # in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many medals were presented to men and how many to women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. medals presented to men and to women in ascending order of values\")\n",
    "print(df.Gender.value_counts(ascending=True,dropna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. medals presented to men and to women in descending order of values\")\n",
    "print(df.Gender.value_counts(ascending=False,dropna=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display athlete column in ascending order - use sort_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Athlete column in ascending order')\n",
    "print(df.Athlete.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display athlete column in descending order - use sort_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Athlete column in descending order\")\n",
    "print(df.Athlete.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### display all columns in sorted order of edition and then athlete. In each column can specify ascending or descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort in more than one column and show all records\n",
    "#Note: How to scpecify ascending or descending if \n",
    "# using more than one column\n",
    "\n",
    "print(df.sort_values(by=['Edition','Athlete'],ascending=[True,False]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sort in more than one column and show all records for specified columns (Edition and Athlete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sort_values(by=['Edition','Athlete'],ascending=[True,False])[['Edition','Athlete']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternatively creat a temporary dataframe.\n",
    "df2=df.sort_values(by=['Edition','Athlete'],ascending=[True,False]) #all columns\n",
    "print(df2[['Edition','Athlete']]) # specific columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sort in more than one column and show Edition and Athlete only DISPLAY SCPEFIC COLUMNS: 'Edition' and 'Athlete'. Note: Another way of thining DataFrame. Select columns first and deal with sorting on selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['Edition','Athlete']].sort_values(by=['Edition','Athlete'],ascending=[True,False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternatively - create a temporary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df[['Edition','Athlete']].copy()\n",
    "print(df2.sort_values(by=['Edition','Athlete'],ascending=[True,False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Gender and Medal columns for women who got a Gold medal -> using Boolean Indexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df[(df.Gender=='Women') & (df.Medal=='Gold')]\n",
    "print(f\"df2=\\n {df2[['Gender','Medal']]}\")\n",
    "      \n",
    "#Can be combined in one statement\n",
    "df5=df[(df.Gender=='Women') & (df.Medal=='Gold')][['Gender','Medal']]\n",
    "print(f'df5=\\n {df5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display how many women got Gold in the whole period. Compare with rows obtained in cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df[(df.Gender=='Women') & (df.Medal=='Gold')]\n",
    "print(f'Number of Women who got the Gold Medal is: {df3.Gender.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Edition, Athlete, and Medal columns where the Athlete name contains the word 'Johannes'. Sort by Edition. Also display how many records meets that condition ->String Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df[df.Athlete.str.contains('Johannes')][['Edition','Athlete','Medal']].sort_values(by='Edition')\n",
    "print(df2)\n",
    "print(f'\\nNumber of Athletes which contains the word Johannes is {df2.Edition.count()}')\n",
    "print('\\nAlternatively')\n",
    "print(f'Number of Athletes which contains the word Johannes is {df2.shape[0]}')\n",
    "print('\\nAlternatively')\n",
    "print(f'Number of Athletes which contains the word Johannes is {df2.Edition.size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display athlete column for records whose Athlete name start with 'AALTONEN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Athlete column for records whose Athlete name start with 'AALTONEN\")\n",
    "df2=df[df.Athlete.str.startswith('AALTONEN')]['Athlete'] #dict style\n",
    "print(df2)\n",
    "print('\\nalternatively')\n",
    "print(\"Athlete column for records whose Athlete name start with 'AALTONEN\")\n",
    "df3=df[df.Athlete.str.startswith('AALTONEN')].Athlete # attribute style\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate using dictionay type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Questions and SAMPLE solutions using olympics.csv\n",
    "#### *Note: In Pandas, there are many ways of doing the same thing!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "In which events did Jesse Owens win a medal. Display the event name \n",
    "and how many times did he participate in that event. TIP: Check how First Name and Last name are recorded in the file/dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 01 solution\n",
    "print(df[df.Athlete=='OWENS, Jesse'].Event.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra: Prove your above answer\n",
    "print(df[df.Athlete=='OWENS, Jesse']['Athlete'])\n",
    "print()\n",
    "print(df[df.Athlete=='OWENS, Jesse'].Event.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "Which athletes has won men's gold medals in singles \n",
    "badminton over the years.  \n",
    "Sort the results alphabetically by the athlete's names.  \n",
    "Display ONLY fields: Edition, Medal, Gender and Sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2 solution\n",
    "df2 = df[(df.Medal == 'Gold') & (df.Gender == 'Men') & (df.Sport == 'Badminton')]\n",
    "print(df2[['Athlete','Medal','Gender','Sport']].sort_values(by='Athlete'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "Which three countries have won the most medals in recent years (from 1984 to 2008)?\n",
    "TIP: value_counts display in descending order. Take the top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3 solution\n",
    "print(df[df.Edition>=1984].NOC.value_counts().head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "Display the male gold medal winners for the 100m track and \n",
    "field sprint (i.e. 100m) event over the years. List the results starting\n",
    "with the most recent years. Display fields: Gender, City,Edition,Athlete and NOC in that order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question4 solution\n",
    "\n",
    "df2 = df[(df.Gender == 'Men') & (df.Medal == 'Gold') & (df.Event == '100m')]\n",
    "df2=df2.sort_values('Edition',ascending=False)[['Gender','City','Edition','Athlete','NOC']]\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby - Group by Edition column and display groups sizes (How many rows for each group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.groupby('Edition').size()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby using more than one key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('olympics.csv',skiprows=4)\n",
    "print(df.groupby(['Edition','NOC','Medal']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df2.groupby(['Team','Year']).Points.agg(['min','max'])\")\n",
    "print(df2.groupby(['Team','Year']).Points.agg(['min','max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df2.groupby(['Team','Year']).agg({'Year':['min','max'], 'Points':['min','max']})\\n\")\n",
    "print(df2.groupby(['Team','Year']).agg({'Year':['min','max'], 'Points':['min','max']}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
